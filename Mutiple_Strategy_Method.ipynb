{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# __Mutiple Strategy Method__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First stage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.Data Preparation\n",
    "\n",
    "Please allocate the data you want to use in proportion to the corresponding folder.Each image needs a corresponding tag file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = r''\n",
    "\n",
    "val_data_path = r''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "channel = input(\"Please enter number of channel\")\n",
    "data_all = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.Image Composition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that each of your image data contains all bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import glob\n",
    "import os\n",
    "\n",
    "fits_file_list = glob.glob(os.path.join(train_data_path ,'\\*.fits'))\n",
    "assert len(fits_file_list) % channel == 0, 'Please check your dataset'\n",
    "for i in range(0, len(fits_file_list), channel):\n",
    "    path = fits_file_list[i][:-7] + '.fits'\n",
    "    for j in range(i, i+channel):\n",
    "        data_all.append(fits.getdata(fits_file_list[j]))\n",
    "\n",
    "    hdu = fits.PrimaryHDU(data_all)\n",
    "    hdul = fits.HDUList([hdu])\n",
    "    hdul.writeto(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.Modification of pre-training weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pretrained_weights = torch.load('mask_rcnn_swin_tiny_patch4_window7.pth')\n",
    "\n",
    "\n",
    "# backbone.patch_embed.proj.weight torch.Size([96, 1, 4, 4])\n",
    "new_pre_trained_weights = torch.empty(size=[64, int(channel), 7, 7])\n",
    "for i in range(0, channel):\n",
    "    new_pre_trained_weights[:, i:i+1, :, :] \\\n",
    "    = pretrained_weights['state_dict']['backbone.patch_embed.proj.weight'][:, :, :, :]\n",
    "\n",
    "pretrained_weights['state_dict']['backbone.patch_embed.proj.weight'] = \\\n",
    "    new_pre_trained_weights['state_dict']['backbone.patch_embed.proj.weight'][:, :, :, :]\n",
    "\n",
    "\n",
    "torch.save(pretrained_weights, r\"E:\\xjbx\\Swin2\\Swin-Transformer-Object-Detection-master\\mask_rcnn_swin_multibrand_%d.pth\" % channel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " default_runtime.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pre_model = r''\n",
    "with open('configs/_base_/default_runtime_1.py', 'r')as f:\n",
    "    content = f.readlines()\n",
    "    print(content[-3])\n",
    "    content[-3] = 'load_from = r\"'  + str(pre_model) + '\"\\n'\n",
    "content\n",
    "with open('configs/_base_/default_runtime_1.py', 'w')as f:\n",
    "    f.writelines(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.Modify network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Calculation of mean and variance for standardisation of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15901898 0.025180187\n",
      "[0.15901898] [0.025180187]\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "\n",
    "# Pick a composite multi-band data\n",
    "data_path = r'E:\\Galaxy_detection\\Swin-Transformer-Object-Detection-master\\data\\coco\\train2017_JWST_galaxy\\jw02736001001_02105_00001_nrca1_i2d_0.fits'\n",
    "data = fits.getdata(data_path)\n",
    "mean = []\n",
    "std = []\n",
    "for i in range(0, int(channel)):\n",
    "    # mean_ = np.mean(data[i, :, :])\n",
    "    # std_ = np.std(data[i, :, :])\n",
    "    mean_ = np.mean(data)\n",
    "    std_ = np.std(data)\n",
    "    mean.append(mean_)\n",
    "    std.append(std_)\n",
    "    print(mean_, std_)\n",
    "print(mean, std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In coco_instance.py, we modify the mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean=[0.05358604],\n",
      "\n",
      "    std=[0.9776479],\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 修改 47行\n",
    "with open('configs/_base_/datasets/coco_instance.py', 'r') as f:\n",
    "    content = f.readlines()\n",
    "    print(content[4])\n",
    "    print(content[5])\n",
    "    mean_str = '    mean=' + str(mean) + ',\\n'\n",
    "    std_str =  '    std=' + str(std) + ',\\n'\n",
    "    content[4] = mean_str\n",
    "    content[5] = std_str\n",
    "content\n",
    "with open('configs/_base_/datasets/coco_instance.py', 'w') as f:\n",
    "    f.writelines(content)\n",
    "    print(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_adamw_3x_coco.py, we modify the mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('configs/swin/mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_adamw_3x_coco.py', 'r')as f:\n",
    "    content = f.readlines()\n",
    "    mean_str = '    mean=' + str(mean) + ',\\n'\n",
    "    std_str =  '    std=' + str(std) + ',\\n'\n",
    "    content[22] = mean_str\n",
    "    content[23] = std_str\n",
    "with open('configs/swin/mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_adamw_3x_coco.py', 'w')as f:\n",
    "    f.writelines(content)\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " In mask_rcnn_swin_fpn.py, we modify the input channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with open('configs/_base_/models/mask_rcnn_swin_fpn.py' , 'r') as f:\n",
    "\n",
    "    content = f.readlines()\n",
    "    in_chans_str = '        in_chans=%s,\\n'%channel,\n",
    "    content[7] = in_chans_str\n",
    "content[7] = content[7][0]\n",
    "content\n",
    "with open('configs/_base_/models/mask_rcnn_swin_fpn.py' , 'w') as f:\n",
    "    f.writelines(content)\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Mutil-Step Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--work-dir WORK_DIR]\n",
      "                             [--resume-from RESUME_FROM] [--no-validate]\n",
      "                             [--gpus GPUS | --gpu-ids GPU_IDS [GPU_IDS ...]]\n",
      "                             [--seed SEED] [--deterministic]\n",
      "                             [--options OPTIONS [OPTIONS ...]]\n",
      "                             [--cfg-options CFG_OPTIONS [CFG_OPTIONS ...]]\n",
      "                             [--launcher {none,pytorch,slurm,mpi}]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             config\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    }
   ],
   "source": [
    "from tools import train\n",
    "\n",
    "train.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Mask Galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mmdet.apis import inference_detector, init_detector\n",
    "\n",
    "configs = r'configs/swin/mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_adamw_3x_coco.py'\n",
    "# Saving catalogue for training weights\n",
    "checkpoints = r''\n",
    "devices = 'cuda:0'\n",
    "\n",
    "model = init_detector(configs, checkpoints, device=devices)\n",
    "# path of training set\n",
    "fits_path = r' '\n",
    "for f_path in fits_path:\n",
    "    base_new_path = r'E:\\xjbx\\Swin2\\Swin-Transformer-Object-Detection-master\\data\\coco\\val2017_multi'\n",
    "    result = inference_detector(model, f_path)\n",
    "    try:\n",
    "        bbox = result[0][0]\n",
    "        img_data = fits.getdata(f_path)\n",
    "        img_data = np.flip(img_data, 0)\n",
    "        for i in range(0, img_data.shape[0]):\n",
    "            for j in range(0, len(result)):\n",
    "                img_data[i][int(bbox[j][1]): int(bbox[j][3]), int(bbox[j][0]): int(bbox[j][2])] = 0\n",
    "        new_fits_path = f_path[-24:-5] + '_mask.fits'\n",
    "        new_fits_path = os.path.join(base_new_path, new_fits_path)\n",
    "        print(new_fits_path)\n",
    "        hdu = fits.PrimaryHDU(img_data)\n",
    "        hdul = fits.HDUList([hdu])\n",
    "        hdul.writeto(new_fits_path)\n",
    "    except:\n",
    "        with open('none_val_result.txt', 'a+') as f:\n",
    "            f.writelines(f_path + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.Data Prepration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = r''\n",
    "\n",
    "val_data_path = r''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.Modify Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "pretrained_weights = torch.load('faster_rcnn_r50_fpn_mstrain_3x_coco_20210524_110822-e10bd31c.pth')\n",
    "\n",
    "\n",
    "# backbone.patch_embed.proj.weight torch.Size([96, 1, 4, 4])\n",
    "new_pre_trained_weights = torch.empty(size=[64, int(channel), 7, 7])\n",
    "for i in range(0, channel):\n",
    "    new_pre_trained_weights[:, i:i+1, :, :] \\\n",
    "    = pretrained_weights['state_dict']['backbone.conv1.weight'][:, 0:1, :, :]\n",
    "\n",
    "pretrained_weights['state_dict']['backbone.patch_embed.proj.weight'] = new_pre_trained_weights\n",
    "\n",
    "\n",
    "torch.save(pretrained_weights, r\"E:\\xjbx\\Swin2\\Swin-Transformer-Object-Detection-master\\faster_rcnn_r50_fpn_mstrain_multibrand_%d.pth\" % channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('configs/_base_/models/fast_rcnn_r50_fpn.py' , 'r') as f:\n",
    "\n",
    "    content = f.readlines()\n",
    "    in_chans_str = '        in_channels=%s,\\n'%channel,\n",
    "    content[6] = in_chans_str\n",
    "content[7] = content[7][0]\n",
    "content\n",
    "with open('configs/_base_/models/fast_rcnn_r50_fpn.py' , 'w') as f:\n",
    "    f.writelines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('configs/_base_/datasets/coco_detection.py', 'r') as f:\n",
    "    content = f.readlines()\n",
    "    print(content[4])\n",
    "    print(content[5])\n",
    "    mean_str = '    mean=' + str(mean) + ',\\n'\n",
    "    std_str =  '    std=' + str(std) + ',\\n'\n",
    "    content[4] = mean_str\n",
    "    content[5] = std_str\n",
    "content\n",
    "with open('configs/_base_/datasets/coco_detection.py', 'w') as f:\n",
    "    f.writelines(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tools import train\n",
    "\n",
    "train.main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.Demo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (955044061.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [2]\u001B[1;36m\u001B[0m\n\u001B[1;33m    for f_path in fi\u001B[0m\n\u001B[1;37m                    ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import inference_detector, init_detector\n",
    "\n",
    "configs = r'configs/faster_rcnn/faster_rcnn_r50_fpn_soft_nms_1x_coco.py'\n",
    "# Saving catalogue for training weights\n",
    "checkpoints = r''\n",
    "devices = 'cuda:0'\n",
    "fits_path = r''\n",
    "model = init_detector(configs, checkpoints, device=devices)\n",
    "for f_path in fits_path:\n",
    "    result = inference_detector(model, f_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# JWST\n",
    "JWST has just made public a new dataset that detects new astronomical targets, and we will use the model to make inferences about that type of data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mmdet.apis import inference_detector, init_detector\n",
    "\n",
    "JWST_PATH = r'E:\\browse download\\google chrome\\jw02736-o001_t001_nircam_clear-f200w_i2d.fits'\n",
    "\n",
    "configs = r'configs/swin/mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_adamw_3x_coco.py'\n",
    "# Saving catalogue for training weights\n",
    "checkpoints = r\"\"\n",
    "devices = 'cuda:0'\n",
    "model = init_detector(configs, checkpoints, device=devices)\n",
    "result = inference_detector(model, JWST_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}